---
description: DSA problem-solving workflow and automation rules
alwaysApply: true
---

# DSA Problem-Solving Workflow Rules

## ‚ö†Ô∏è CRITICAL RULE #0: NEVER MODIFY USER'S SOLUTION CODE

**BEFORE ANY ACTION, CHECK THIS RULE FIRST:**

**ABSOLUTELY FORBIDDEN:**
- NEVER modify, edit, refactor, or change the user's solution method/function
- NEVER touch the logic/algorithm code written by the user
- NEVER change formatting, spacing, or style in solution methods
- NEVER "improve" or "optimize" the user's solution code
- NEVER fix bugs in solution code unless explicitly asked

**ONLY modify solution code when:**
- User explicitly says: "fix my solution", "change my code", "update my implementation"
- User asks for debugging help on their solution
- User requests refactoring or optimization

**What you CAN modify without asking:**
- Main function and test cases (setup code)
- Documentation and comments
- Progress tracker files
- README and non-solution files

**When in doubt:** Ask the user before touching any solution method.

---

## Rule 1: Start - Problem Setup from Links

When a user shares a link to a DSA problem (LeetCode, HackerRank, etc.):

**DO:**
- Fetch and read the problem description from the link
- Create an empty solution method stub (signature only, with `// TODO` inside)
- Create reusable private helper methods for test execution to avoid repetitive code:
  - A `runTest` helper that accepts test number, input, expected output, actual output, and description
  - A `printSummary` helper that prints the final test results table and statistics
- Create a `main` function that uses the helpers to run comprehensive test cases covering:
  - All examples from the problem
  - Edge cases (empty input, single element, minimum/maximum constraints)
  - Normal cases and boundary cases
- Add detailed JavaDoc documentation including:
  - Problem number, title, and difficulty
  - Problem description and constraints
  - Placeholder for approach, time and space complexity
- Add the new problem as üîÑ In Progress in PROGRESS.md (table + daily log + category)

**Code Quality:**
- Keep test code DRY - extract common patterns into helper methods
- Each test case should be a single method call with clear parameters
- Test summary should use stored results, not inline comparisons

**DO NOT:**
- Never create the solution class or solution method logic
- Never implement the actual algorithm
- The user will implement the solution themselves

---

## Rule 2: Analyse - Evaluate User's Solution

When the user asks to analyse/evaluate their solution:

**DO:**
- Read the user's solution code carefully
- List what was done RIGHT (correct patterns, good practices)
- List what was done WRONG or could be improved
- Analyse time and space complexity
- Suggest better approaches with code examples and complexity comparison
- Include a comparison table of all approaches

**DO NOT:**
- NEVER modify the user's solution code (Rule #0)
- Do not create files or update documentation at this step

---

## Rule 3: Compare - Evaluate External Solutions

When the user shares another solution (from LeetCode, interviews, etc.) for comparison:

**DO:**
- Trace through the external solution step-by-step using a test case if requested
- Compare with user's solution on: correctness, complexity, readability, performance
- Explain WHY one performs better than the other
- Cover real-world factors: cache locality, constant factors, method overhead, JIT optimization
- Highlight when LeetCode benchmarks can be misleading vs production reality

**DO NOT:**
- NEVER modify the user's solution code (Rule #0)
- Do not create files or update documentation at this step

---

## Rule 4: Summarise - Consolidate Learnings

When the user asks for a summary of the current problem:

**DO:**
- Compile all learnings from the conversation into a structured summary
- Cover: problem understanding, approaches explored, evolution of solution, key insights
- Include performance analysis, pattern recognition, and best practices learned
- Highlight what to remember for future problems

**DO NOT:**
- NEVER modify the user's solution code (Rule #0)
- Do not create or update any files at this step - this is a conversation-only step

---

## Rule 5: Current - Session Resume & Status Overview

When the user wants a status check or is resuming after a break:

**DO:**
1. Read PROGRESS.md to determine:
   - Last update date
   - Overall statistics (total solved, categories, streak)
   - Any problem marked üîÑ In Progress in the Overview Table
2. If a problem is In Progress:
   - Read the problem file to check solution method status (empty TODO vs implemented)
   - Determine which workflow step was last completed:
     - **Start**: File exists, solution method is empty/TODO
     - **Solving**: Solution method has code but tests may be failing
     - **Analyse/Compare**: Solution works, user was exploring alternatives
     - **Update pending**: Solution done but docs/tracker not yet updated
     - **GitPush pending**: Everything updated but not committed
3. Present a concise status report:
   - üìä Overall Stats (total solved, streak, categories)
   - üìã Last 3 problems from Overview Table
   - üîÑ Current Problem (if any): name, link, status, last workflow step
   - üìÅ Uncommitted changes (run `git status`)
   - üéØ Suggested next action

**Format the report clearly with sections, not walls of text.**

**DO NOT:**
- Do not modify any files
- Do not start new problems
- This is a read-only status check

---

## Rule 6: Update - Documentation & Progress Tracking


When the user asks to update documentation and progress:

**DO:**
- Update JavaDoc in the problem file with:
  - Final solution approach
  - Time and space complexity
  - Key learnings and alternative approaches
  - Do NOT touch the solution code itself (Rule #0)
- Update PROGRESS.md:
  - Mark problem as ‚úÖ Done in the Overview Table (fill in complexity, AI help)
  - Complete the Daily Progress Log entry with approach, complexity, learnings, AI status
  - Update category checklist
  - Add new entries to Key Learnings and Patterns Identified sections
  - Update Summary Statistics (total solved, in progress, streak)
- Update README.md:
  - Update category table count
  - Update statistics section

---

## Rule 7: GitPush - Commit and Push

When the user asks to commit and push:

**DO:**
1. Run `git status` and `git diff --stat` to review changes
2. Stage all changes with `git add .`
3. Create a descriptive commit message including:
   - Problem number, name, and brief description
   - Solution approach and complexity
   - Key learnings (brief)
   - List of files changed
4. Push to remote with `git push origin main`
5. Verify with `git status` to confirm clean state

---

## Progress Tracker Format

### Problems Overview Table Format
Each row should include:
- Sequential number
- Date (YYYY-MM-DD format)
- Problem name with link and number
- Difficulty (Easy/Medium/Hard)
- Category
- Time complexity (Big O notation)
- Space complexity (Big O notation)
- AI Help (‚úÖ Yes / ‚ùå No) - **Only mark Yes if AI helped with solution/algorithm logic**
- Status (‚úÖ Done / üîÑ In Progress)

### Daily Progress Log Format
Each entry should include:
- Date and time
- Problem name and number
- Problem link
- Brief approach (1-2 sentences)
- Time complexity
- Space complexity
- AI assistance: [Yes/No] with specific details

### AI Assistance Definition
**AI assistance = ‚úÖ Yes** ONLY when:
- AI helped write the solution class/method
- AI provided the algorithm logic or approach
- AI debugged or fixed the solution code

**AI assistance = ‚ùå No** when:
- AI only created main function and test cases (this is expected)
- AI only added documentation/comments
- User implemented the entire solution independently

### Summary Statistics to Update
- Total Problems Solved count
- Categories Covered list
- Current Streak
